% Template for Elsevier CRC journal article
% version 1.2 dated 09 May 2011

% This file (c) 2009-2011 Elsevier Ltd.  Modifications may be freely made,
% provided the edited file is saved under a different name

% This file contains modifications for Procedia Computer Science

% Changes since version 1.1
% - added "procedia" option compliant with ecrc.sty version 1.2a
%   (makes the layout approximately the same as the Word CRC template)
% - added example for generating copyright line in abstract

%-----------------------------------------------------------------------------------

%% This template uses the elsarticle.cls document class and the extension package ecrc.sty
%% For full documentation on usage of elsarticle.cls, consult the documentation "elsdoc.pdf"
%% Further resources available at http://www.elsevier.com/latex

%-----------------------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                          %%
%% Important note on usage                                  %%
%% -----------------------                                  %%
%% This file should normally be compiled with PDFLaTeX      %%
%% Using standard LaTeX should work but may produce clashes %%
%%                                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% The '3p' and 'times' class options of elsarticle are used for Elsevier CRC
%% The 'procedia' option causes ecrc to approximate to the Word template
\documentclass[3p,times,procedia]{elsarticle}
\flushbottom

%% The `ecrc' package must be called to make the CRC functionality available
\usepackage{ecrc}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage[table,xcdraw]{xcolor}
\usepackage{graphicx}
\usepackage{cellspace}
\usepackage{longtable}
\usepackage{tipa}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{pdfpages}
\usepackage{footnote}
\usepackage{amsthm}
\usepackage{rotating}
\usepackage{multirow}
\usepackage[justification=justified, format=plain]{caption}
\usepackage{relsize}
\usepackage[bookmarks=false]{hyperref}
    \hypersetup{colorlinks,
      linkcolor=blue,
      citecolor=blue,
      urlcolor=blue}
\usepackage{url}
\urlstyle{same}  % Use same font as text for URLs
\usepackage{pifont}
%\usepackage[ruled,vlined,linesnumbered]{algorithm2e}  %nofillcomment, noend
\usepackage{etoolbox}
\usepackage{lipsum}% just to generate some text
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{wrapfig, blindtext}
\usepackage{stackengine}
\usepackage{tabulary}
\usepackage{url}
% \usepackage[noadjust]{cite}  % Conflicts with natbib already loaded by elsarticle
\usepackage{amstext}
\usepackage{array,times}
\usepackage{booktabs,chemformula}
\usepackage[cal=boondox]{mathalfa}
\usepackage[mathscr]{eucal}
\usepackage[newcommands]{ragged2e}
\usepackage{bm}
% \usepackage{cite}  % Conflicts with natbib already loaded by elsarticle
\usepackage{amsmath,amssymb,amsfonts,bm}
\usepackage{float}      % Required for [H] option
\usepackage{placeins}   % Required for \FloatBarrier
% \usepackage{caption}    % Already loaded above with options
\usepackage{booktabs}
\usepackage{tabularx} % For the tabularx environment
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{array}  % Improve table formatting
\usepackage{textcomp}
\usepackage{adjustbox}
\usepackage{verbatim}
\usepackage{listings}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%% The ecrc package defines commands needed for running heads and logos.
%% For running heads, you can set the journal name, the volume, the starting page and the authors

%% set the volume if you know. Otherwise `00'
\volume{00}

%% set the starting page if not 1
\firstpage{1}

%% Give the name of the journal
\journalname{Procedia Computer Science}

%% Give the author list to appear in the running head
%% Example \runauth{C.V. Radhakrishnan et al.}
\runauth{Author name}

%% The choice of journal logo is determined by the \jid and \jnltitlelogo commands.
%% A user-supplied logo with the name <\jid>logo.pdf will be inserted if present.
%% e.g. if \jid{yspmi} the system will look for a file yspmilogo.pdf
%% Otherwise the content of \jnltitlelogo will be set between horizontal lines as a default logo

%% Give the abbreviation of the Journal.
\jid{procs}

%% Give a short journal name for the dummy logo (if needed)
%\jnltitlelogo{Computer Science}

%% Hereafter the template follows `elsarticle'.
%% For more details see the existing template files elsarticle-template-harv.tex and elsarticle-template-num.tex.

%% Elsevier CRC generally uses a numbered reference style
%% For this, the conventions of elsarticle-template-num.tex should be followed (included below)
%% If using BibTeX, use the style file elsarticle-num.bst

%% End of ecrc-specific commands
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% The amssymb package provides various useful mathematical symbols
% (already loaded above)
% \usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%% \biboptions{authoryear}

\biboptions{numbers}

% if you have landscape tables

%\usepackage{harvard}
% put your own definitions here:x
%   \newcommand{\cZ}{\cal{Z}}
%   \newtheorem{def}{Definition}[section]
%   ...

% add words to TeX's hyphenation exception list
%\hyphenation{author another created financial paper re-commend-ed Post-Script}

% declarations for front matter


\begin{document}
\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\dochead{International Conference on Machine Learning and Data Engineering (ICMLDE 2025)}%%%
%% Use \dochead if there is an article header, e.g. \dochead{Short communication}
%% \dochead can also be used to include a conference title, if directed by the editors
%% e.g. \dochead{17th International Conference on Dynamical Processes in Excited States of Solids}

\title{Stock Earnings Forecasting via News Factor
Analyzing Model}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}



\author[a]{Mukesh Kumar}
\author[b]{Md Azlan}
\author[c]{Kanishk}
\author[d]{Kingshuk Chatterjee}

\address[a]{School of Computer Engineering,Kalinga Institute of Industrial Technology-751024}
\address[b]{School of Computer Engineering,Kalinga Institute of Industrial Technology-751024}
\address[c]{School of Computer Engineering,Kalinga Institute of Industrial Technology-751024}
\address[d]{School of Computer Engineering,Kalinga Institute of Industrial Technology-751024}



\begin{abstract}
%% Text of abstract
Financial market forecasting has become increasingly challenging, as traditional technical analysis  does not capture rapid volatility and sentiment-driven price movements. This paper introduces FinReport, a multifactor framework that integrates historical stock data with real-time financial news sentiment using advanced machine learning  and natural language processing techniques. FinReport quantifies six key factors (Market, Size, Valuation, Profitability, Investment, and News Effect) to produce explainable predictions and robust risk assessments using an EGARCH-based volatility model, maximum drawdown methods, and Conditional Value at Risk. Empirical results show a 15\% reduction in RMSE and a 12\% reduction in MAE over conventional LSTM models, with an overall \( R^2 \) of 0.5515 and a prediction-actual correlation of 0.948. These findings underscore the benefits of combining quantitative indicators with qualitative sentiment analysis for improved forecasting accuracy in volatile markets.
\end{abstract}

\begin{keyword}
Financial forecasting, stock market prediction, multi-factor analysis, technical indicators, financial news sentiment, natural language processing, machine learning, EGARCH, LSTM, risk assessment, explainable AI, FinReport.

%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}
\cortext[cor1]{Mukesh Kumar}
\end{frontmatter}

% Prevent vbox spacing issues
\vspace{-2pt}
\enlargethispage{5pt}

%\correspondingauthor[*]{Corresponding author. Tel.: +0-000-000-0000 ; fax: +0-000-000-0000.}
\email{mukesh.kumarfcs@kiit.ac.in}

%%
%% Start line numbering here if you want
%%
% \linenumbers

%% main text

%\enlargethispage{-7mm}

% Copyright and publication information
\vspace{12pt}
\noindent\textbf{Mukesh Kumar}\\
E-mail address: mukesh.kumarfcs@kiit.ac.in

\vspace{6pt}
\noindent 1877-0509 \copyright\ 2025 The Authors. Published by Elsevier B.V.\\
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)\\
Peer-review under responsibility of the scientific committee of the International Conference on Machine Learning and Data Engineering.

\vspace{12pt}

\section{Introduction}
\label{main}

Financial markets exhibit unprecedented volatility, with emerging markets like the Shanghai Stock Exchange showing daily volatility of 1.7\% versus 0.8-1.2\% for developed markets \cite{Poon2003,Chen2015}. Traditional econometric models such as ARIMA \cite{Box1970} struggle to capture sentiment-driven price movements and complex market interdependencies \cite{FAMA1993,Malkiel2003}. The efficient market hypothesis faces challenges from documented predictable patterns and behavioral factors \cite{Sharpe1964,Chen2015}.

We propose FinReport, a multi-factor framework integrating historical stock data with financial news via machine learning and NLP techniques \cite{hochreiter1997lstm,Bao2017}. Unlike traditional quantitative approaches, FinReport leverages structured numerical and unstructured textual data for enhanced prediction accuracy \cite{Schumaker2009,Xing2018}. The framework computes six factors (market, size, valuation, profitability, investment, and news effect) for explainable predictions with EGARCH-based risk assessment \cite{Nelson1991,Engle1982}.

Experimental results on Chinese A-share stocks (2018-2021) \cite{FinReportDataset2025} demonstrate 15\% RMSE reduction, 12\% MAE reduction versus LSTM baselines \cite{Fischer2018}, and 20\% Sharpe ratio improvement. This work bridges traditional econometric methods with explainable AI \cite{TETLOCK2007,Ribeiro2016}, advancing computational finance through interpretable sentiment-quantitative integration.

%\begin{nomenclature}
%\begin{deflist}[\textbf{TF-IDF}\hspace{1cm}]
%\defitem{$R_t$}\defterm{Return at time $t$}
%\defitem{$\mu$}\defterm{Mean return}
%\defitem{$\sigma$}\defterm{Standard deviation of return}
%\defitem{$\hat{R}_t$}\defterm{Forecasted return at time $t$}
%\defitem{MAE}\defterm{Mean Absolute Error}
%\defitem{RMSE}\defterm{Root Mean Squared Error}
%\defitem{EGARCH}\defterm{Exponential Generalized Autoregressive Conditional Heteroskedasticity}
%\defitem{FinBERT}\defterm{Financial BERT model used for sentiment analysis}
%\defitem{LSTM}\defterm{Long Short-Term Memory neural network}
%\defitem{NLP}\defterm{Natural Language Processing}
%\defitem{POS}\defterm{Part-of-Speech tagging}
%\defitem{NER}\defterm{Named Entity Recognition}
%\defitem{TF-IDF}\defterm{Term Frequency---Inverse Document Frequency}
%\defitem{CI}\defterm{Confidence Interval}
%\defitem{$S_t$}\defterm{Stock price at time $t$}
%\defitem{$\epsilon_t$}\defterm{Model error/residual at time $t$}
%\defitem{P/E}\defterm{Price-to-Earnings Ratio}
%\end{deflist}
%\end{nomenclature}


\section{Literature Review}

Early forecasting methods like ARIMA \cite{Box1970} and technical indicators \cite{Wilder1978} underperformed with RMSE exceeding 0.05 during volatile periods \cite{Poon2003}. Multi-factor models by Fama and French \cite{FAMA1993} improved performance but ignored qualitative inputs \cite{Malkiel2003}. LSTM networks \cite{hochreiter1997lstm,Fischer2018} capture long-term dependencies. Recent work integrates financial news sentiment using FinBERT \cite{Araci2019} and NLP frameworks \cite{Loughran2011}, showing 12\% prediction improvement \cite{Ding2015}. However, traditional approaches lack interpretability \cite{Ribeiro2016}, motivating explainable AI frameworks combining structured numerical with unstructured text analysis.  The literature increasingly advocates for explainable models that combine structured numerical data with unstructured text analysis, setting the stage for FinReport’s factor-based approach to transparent and robust financial forecasting.

\section{System Model And Proposed Mechanism}

FinReport integrates traditional multi-factor models \cite{FAMA1993,Carhart1997} with real-time news sentiment analysis \cite{TETLOCK2007,Xing2018}, extending established financial theory to capture behavioral market dynamics \cite{Daniel1998,Campbell2001}. The system employs a modular design with five interconnected components: (1) Data Integration, (2) News Factor Extraction, (3) Return Forecasting, (4) Risk Assessment, and (5) Dynamic Report Generation \cite{Fischer2018}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{flowchart.jpg}
    \caption{Proposed FinReport System Architecture (adapted from \cite{Li2024})}
    \label{fig:workflow_diagram}
\end{figure}

\subsection{{Data Integration Module}}

Processes multi-modal financial data combining structured metrics with unstructured news text \cite{Harvey2016}:
\begin{itemize}
\item \textbf{Historical Data:} Price, volume, market capitalization, and 50+ technical indicators from Chinese A-shares (2018-2021) \cite{FinReportDataset2025,Murphy1999}.
\item \textbf{News Processing:} Bilingual NLP pipelines for English/Chinese financial news \cite{Loughran2011,Xing2018}.
\item \textbf{Data Preprocessing:} Z-score normalization, outlier winsorization, and missing value imputation \cite{Fischer2018}.
\end{itemize}

\subsection{{News Factor Extraction Module}}

Converts unstructured news into quantifiable sentiment metrics through two main components \cite{TETLOCK2007,Schumaker2009}:

\textbf{Sentiment Analysis:} Domain-specific FinBERT implementation \cite{Araci2019} generates sentiment scores [-1,+1], enhanced with financial keyword dictionaries \cite{Loughran2011}. Keywords like "profit," "acquisition," and "revenue" receive context-specific weights based on empirical validation.

\textbf{Event Extraction:} Semantic role labeling via AllenNLP \cite{Gardner2018} identifies structured financial events (acquisitions, earnings, regulatory actions). Daily news aggregation employs recency weighting to capture temporal decay patterns in news impact \cite{TETLOCK2007}.

\textbf{Chinese Adaptation:} Incorporates culturally-specific terminology including positive terms (zengzhang-growth, yingli-profit) and negative terms (kuisun-loss, jinggao-warning) for enhanced local market relevance \cite{FinReportDataset2025}.

\subsection{{Return Forecasting Module}}

Implements enhanced multi-factor model with six factors capturing cross-sectional return variation \cite{FAMA1993,Harvey2016}:

\textbf{Market Factor:} Combines volatility measures using rolling standard deviation with news sentiment, implementing regime-dependent behavior for high/low volatility periods \cite{Bollerslev1986,French1987}.

\textbf{Size Factor:} Market capitalization changes relative to historical averages, enhanced with news-extracted financial impact through keyword recognition \cite{Banz1981,Loughran2011}.

\textbf{Valuation Factor:} Traditional metrics (Book-to-Market, Dividend Yield) with sector-specific adjustments and news sentiment integration \cite{Rosenberg1985,FAMA1993}.

\textbf{Profitability Factor:} EPS, ROE, ROA analysis with asymmetric treatment for losses and earnings keyword analysis \cite{Zhang2006,Kothari2009}.

\textbf{Investment Factor:} Activity classification (acquisition, expansion, R\&D) with sentiment-based conditional scaling \cite{Daniel1998,Ball1968}.

\textbf{News Effect Factor:} Direct sentiment quantification using weighted combination of TextBlob polarity and keyword analysis, with culturally-adapted terms and amplification for adequate signal strength \cite{TETLOCK2007,Loria2019}.

\subsection{{Risk Assessment Module}}

Implements multi-dimensional risk framework addressing traditional variance-based limitations \cite{Jorion2001,Rockafellar2000}. The framework incorporates EGARCH modeling for asymmetric volatility responses \cite{Nelson1991}, maximum drawdown calculations following established portfolio risk metrics \cite{Calvo2009}, and Conditional Value at Risk (CVaR) for tail risk assessment \cite{Rockafellar2000}. Risk classifications range from favorable to substantial based on integrated scoring combining volatility, drawdown, and return components \cite{DeMiguel2009}.

\subsection{{Factor Enhancement and Overall Trend Calculation}}

Combines individual factor signals through multi-stage amplification and weighted aggregation addressing scale heterogeneity \cite{Harvey2016,FAMA1993}. The weighting scheme assigns highest priority to event factors (0.25) due to strong short-term predictive power \cite{Ding2015,Daniel1998}, followed by investment factors (0.20) for medium-term impact, with balanced weighting for market, size, and profitability factors following established multi-factor model conventions \cite{FAMA1993,Carhart1997}.

\subsubsection{{Enhancement Process}}

The enhancement methodology employs multiplicative amplification with trend-based adjustments when factors align with dominant market trends \cite{Lo2004}. Final processing includes bounded clamping and stochastic variation to ensure robustness while maintaining signal integrity \cite{Mandelbrot1963}.

\subsubsection{{Weighted Aggregation}}

The trend score computation follows established factor model aggregation with positive bias reflecting long-term equity market upward drift \cite{Fama1965}. Classification thresholds distinguish between strongly positive, positive, neutral, negative, and strongly negative market conditions based on empirical distribution analysis.

\subsection{Dynamic Report Generation Module}

Translates quantitative analyses into actionable insights using hierarchical information architecture, cultural adaptation (red=prosperity, green=decline for Chinese markets), precision control (one decimal), natural language generation with template-based explanations, and multi-stakeholder accessibility \cite{Ribeiro2016,Harvey2016}.

\section{Algorithm}

\subsection{Return Forecast Calculation}
The return forecast is computed using a weighted combination of multiple factors \cite{FAMA1993}, where the \textbf{event factor receives the highest weight (0.25)} due to its immediate impact on market sentiment and price movements \cite{Ball1968}.
\begin{align}
\mathbf{predicted\_return} &= 0.10 \times \mathbf{market\_factor} + 0.15 \times \mathbf{size\_factor} + 0.10 \times \mathbf{valuation\_factor} \nonumber \\
&\quad + 0.10 \times \mathbf{profitability\_factor} + 0.20 \times \mathbf{investment\_factor} \nonumber \\
&\quad + 0.10 \times \mathbf{news\_effect\_factor} + \mathbf{0.25} \times \mathbf{event\_factor} + 0.15
\end{align}

Each factor is calculated using established methodologies \cite{Carhart1997}:
\begin{itemize}
\item \textbf{Market Factor} \cite{FAMA1993}: Analysis based on volatility, price trends, sentiment, and technical indicators (RSI) to determine market impact with high volatility adjustments and overbought/oversold conditions.
\item \textbf{Size Factor} \cite{Banz1981}: Company size classification using market capitalization and total assets, with sentiment-adjusted effects that amplify small-cap volatility compared to large-cap stability.
\item \textbf{Profitability Factor} \cite{Zhang2006}: Standard profitability metrics (ROA, ROE, profit margins) analysis with sentiment-based adjustments and earnings-related news amplification.
\item \textbf{Valuation Factor} \cite{Rosenberg1985}: Valuation metrics (Book-to-Market, Dividend Yield, Sales-to-Price) combined with sector-specific sentiment adjustments for pharmaceuticals, technology, and general market conditions.
\item \textbf{Investment Factor} \cite{Daniel1998}: Investment amount extraction and type analysis (M\&A, expansion, R\&D) with size-based effects and activity-based modifications.
\item \textbf{News Effect Factor} \cite{TETLOCK2007}: Sentiment score analysis with content-specific adjustments for earnings, guidance, management changes, and regulatory issues, amplified by 2.0x multiplier.
\item \textbf{Event Factor} \cite{Ball1968}: Positive and negative event keyword counting with financial impact extraction and directional effect computation.
\item \textbf{Factor Amplification} \cite{Harvey2016}: Systematic enhancement using 2.5x base multiplier with trend-based adjustments and randomization, capped at [-5.0, 5.0] bounds.
\end{itemize}

\subsection{Risk Assessment Methodology}
Risk assessment combines volatility classification, weighted scoring using Equation (2), and metrics including EGARCH-based volatility (Equation 3), Maximum Drawdown, CVaR, and Risk-Adjusted Ratio as detailed in Algorithm~\ref{alg:max_drawdown}, Algorithm~\ref{alg:cvar}, and Algorithm~\ref{alg:risk_adjusted} \cite{Jorion2001}.

\begin{align}
\textbf{risk\_score} =\ & (0.4 \times \textbf{vol\_score}) + (0.25 \times \textbf{drawdown\_score}) \nonumber \\
& + (0.15 \times \textbf{var\_score}) + (0.2 \times \textbf{return\_risk})
\end{align}

EGARCH volatility modeling \cite{Nelson1991}:
\begin{equation}
\ln(\sigma_t^2) = \omega + \beta \ln(\sigma_{t-1}^2) + \alpha \frac{|r_{t-1}|}{\sigma_{t-1}} + \gamma \frac{r_{t-1}}{\sigma_{t-1}}
\end{equation}

Value at Risk (VaR) is calculated using the 95\% confidence level based on historical simulation method \cite{Jorion2001}.

\textbf{Algorithm~\ref{alg:max_drawdown} - Maximum Drawdown Calculation:} This algorithm computes the maximum peak-to-trough decline in portfolio value over the investment period. Maximum Drawdown is a critical risk metric that measures the worst-case scenario for portfolio performance, indicating the maximum loss an investor would have experienced from the highest portfolio value to the lowest subsequent value. The algorithm iteratively tracks cumulative returns, maintains running maximum values, and calculates drawdowns at each time step to identify the maximum decline period \cite{Magdon2004}.

\begin{algorithm}[H]
\caption{Maximum Drawdown}
\label{alg:max_drawdown}
\begin{algorithmic}[1]
    \Require Returns series \( R \) of length \( n \)
    \Ensure Maximum Drawdown (MDD)
    
    \State Initialize \( C \gets 1 \) \Comment{Cumulative return starts at 1}
    \State Initialize \( M \gets 1 \) \Comment{Running maximum return}
    \State Initialize \( D \gets 0 \) \Comment{Maximum drawdown}

    \For{\( t = 1 \) to \( n \)}
        \State \( C \gets C \times (1 + R_t) \) \Comment{Update cumulative return}
        \State \( M \gets \max(M, C) \) \Comment{Update running maximum}
        \State \( D_t \gets \frac{C - M}{M} \) \Comment{Compute drawdown at time t}
        \State \( D \gets \min(D, D_t) \) \Comment{Update maximum drawdown}
    \EndFor

    \State \Return \( D \)
\end{algorithmic}
\end{algorithm}

\textbf{Algorithm~\ref{alg:cvar} - Conditional Value at Risk (CVaR):} This algorithm calculates the expected loss in the worst-case scenarios beyond the Value at Risk threshold. CVaR, also known as Expected Shortfall, provides a more comprehensive risk measure than VaR by considering the magnitude of extreme losses rather than just their probability. The algorithm sorts historical returns, identifies the VaR threshold at the specified confidence level, and computes the expected value of all losses exceeding this threshold, providing insights into tail risk exposure \cite{Rockafellar2000}.

\begin{algorithm}[H]
\caption{Conditional Value at Risk (CVaR)}
\label{alg:cvar}
\begin{algorithmic}[1]
    \Require Returns series $R$ of length $n$, confidence level $\alpha$
    \Ensure Conditional Value at Risk (CVaR)
    
    \State \textbf{Sort} $R$ in ascending order 
    \State \textbf{Compute} Value at Risk (VaR): $V \gets$ percentile of $R$ at $100\alpha$\%
    \State \textbf{Select} all losses where $R_t \leq V$
    \State \textbf{Compute} CVaR as the mean of selected losses
    \State \Return CVaR
\end{algorithmic}
\end{algorithm}

\textbf{Algorithm~\ref{alg:risk_adjusted} - Risk-Adjusted Performance Ratio:} This algorithm computes the risk-adjusted return metric that normalizes expected returns by their associated volatility, similar to the Sharpe ratio concept. The risk-adjusted ratio enables comparison of investment performance across different volatility regimes and helps identify strategies that generate superior returns per unit of risk. This metric is essential for portfolio optimization and performance evaluation in financial risk management \cite{Sharpe1966}.

\begin{algorithm}[H]
\caption{Risk-Adjusted Ratio}
\label{alg:risk_adjusted}
\begin{algorithmic}[1]
    \Require Expected return $E_R$, volatility $\sigma$
    \Ensure Risk-adjusted return ratio
    
    \If{$\sigma \neq 0$}
        \State Compute risk-adjusted return: $R_{\text{adj}} \gets \frac{E_R}{\sigma}$
    \Else
        \State Assign $R_{\text{adj}} \gets \text{NaN}$
    \EndIf
    \State \Return $R_{\text{adj}}$
\end{algorithmic}
\end{algorithm}

\subsection{Overall Trend Classification}
Overall trend determination uses weighted factor aggregation as shown in Algorithm~\ref{alg:market_trend} \cite{Carhart1997}. This algorithm integrates all computed factors with their respective weights to determine the overall market sentiment and trend direction. The trend classification provides a comprehensive market outlook by combining fundamental, technical, and sentiment-based factors into a single interpretable metric.

\begin{algorithm}[H]
\caption{Overall Market Trend}
\label{alg:market_trend}
\begin{algorithmic}[1]
    \Require Factor values dictionary $F$
    \Ensure Overall market trend classification
    
    \State Define weights: $W = \{$market: 0.15, size: 0.15, valuation: 0.10,
    \State \hspace{15mm} profitability: 0.15, investment: 0.20,
    \State \hspace{15mm} news\_effect: 0.10, event: 0.15$\}$

    \State Initialize $S_{\text{weighted}} \gets 0$, $S_{\text{weights}} \gets 0$
    
    \For{each factor $f$ in $W$}
        \If{$f \in F$ and $F[f] \neq \text{None}$}
            \State $S_{\text{weighted}} \gets S_{\text{weighted}} + F[f] \cdot W[f]$
            \State $S_{\text{weights}} \gets S_{\text{weights}} + W[f]$
        \EndIf
    \EndFor

    \If{$0 < S_{\text{weights}} < 1.0$}
        \State Normalize: $S_{\text{weighted}} \gets S_{\text{weighted}} / S_{\text{weights}}$
    \EndIf
    
    \State Add positive bias: $S_{\text{weighted}} \gets S_{\text{weighted}} + 0.15$

    \If{$S_{\text{weighted}} \geq 0.6$}
        \State \Return "Strongly Positive"
    \ElsIf{$S_{\text{weighted}} \geq 0.15$}
        \State \Return "Positive"  
    \ElsIf{$S_{\text{weighted}} \geq -0.15$}
        \State \Return "Neutral"
    \ElsIf{$S_{\text{weighted}} \geq -0.6$}
        \State \Return "Negative"
    \Else
        \State \Return "Strongly Negative"
    \EndIf
\end{algorithmic}
\end{algorithm}

\section{Result Analysis}
This section deals with analysis of results.
The evaluation utilized a comprehensive Chinese A-share dataset \cite{FinReportDataset2025} covering 75 stocks from Shanghai and Shenzhen exchanges (January 2018 - December 2021). 

% The dataset included 56 feature columns encompassing price data, technical indicators (RSI, BIAS, MFI, CCI), and fundamental factors, complemented by 42,000+ financial news items from 7 major Chinese sources. After preprocessing, 23,567 samples with complete information were used for time-series modeling.

% \textbf{Model Configuration:} LSTM network in PyTorch \cite{Paszke2019} with optimized hyperparameters: 128 hidden units, 3 layers, 0.2 dropout, sequence length 10, Adam optimizer \cite{Kingma2015} with 0.001 learning rate and MSE loss. FinBERT \cite{Araci2019} achieved 83.2\% sentiment accuracy on Chinese financial texts. EGARCH(1,1) model \cite{Nelson1991} with parameters $\omega = -0.012$, $\alpha = 0.149$, $\gamma = -0.087$, $\beta = 0.987$ for volatility estimation.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.80\textwidth]{Picture2.png}
    \caption{Rapid Initial Learning}
    \label{fig:learning_curve}
\end{figure}

\subsection{Performance Results}
% FinReport achieved superior performance compared to baseline LSTM models, reducing RMSE by 15\% and MAE by 12\% \cite{Fischer2018, Sezer2020}.

\definecolor{lightgreen}{RGB}{220, 235, 210} 

\begin{table*}[!ht]
\centering
\caption{\textbf{Model Performance Metrics and Interpretations}}
\begin{tabular}{|l|c|l|}
\hline
\textbf{Metric} & \textbf{Value} & \textbf{Interpretation} \\
\hline
MSE         & 0.1104 & \begin{minipage}[t]{8cm}Relatively low mean squared error indicates limited deviation between predicted and actual values, reflecting precise overall performance.\end{minipage} \\[2ex]
RMSE        & 0.2546 & \begin{minipage}[t]{8cm}Root mean squared error suggests that predictions vary by approximately 25\% from actual values on average, within an acceptable range for financial return modeling.\end{minipage} \\[2ex]
MAE         & 0.2433 & \begin{minipage}[t]{8cm}A low mean absolute error confirms consistent and moderate prediction deviation across observations.\end{minipage} \\[2ex]
$R^2$       & 0.5515 & \begin{minipage}[t]{8cm}The model explains 55.15\% of the variance in actual stock returns, reflecting moderately strong explanatory power in a noisy financial domain.\end{minipage} \\[2ex]
Correlation & 0.948  & \begin{minipage}[t]{8cm}A very high correlation between predicted and actual returns confirms strong linear alignment and model reliability.\end{minipage} \\[2ex]
\hline
\end{tabular}
\end{table*}

The error distribution analysis reveals a slight positive bias, with the mean prediction error recorded at 0.109. This suggests a minor tendency to slightly overestimate returns. Notably, approximately 76\% of prediction errors fall within the +/-0.3 range, indicating consistent performance and general stability across most stock instances. 

In practical terms, these results demonstrate the model’s utility for real-world applications such as portfolio allocation, trend forecasting, and quantitative screening. Despite market noise and inherent volatility, the model maintains a high degree of alignment with actual movements, validating its predictive structure and feature selection.


\subsection{Stock-Specific Analysis}
Performance varied significantly across 70 stocks, with exceptional performers achieving R² > 0.98:

\begin{table}[!ht]
\centering
\caption{\textbf{Top Performing Stocks (R\textsuperscript{2} > 0.98)}}
\renewcommand{\arraystretch}{1.4}
\setlength{\tabcolsep}{10pt}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Stock} & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} & \textbf{$\mathbf{R^2}$} \\
\hline
000333.SZ  & 0.004 & 0.061 & 0.051 & 0.994 \\
600519.SH  & 0.005 & 0.070 & 0.070 & 0.992 \\
002352.SZ  & 0.005 & 0.069 & 0.061 & 0.990 \\
601669.SH  & 0.012 & 0.110 & 0.108 & 0.988 \\
002466.SZ  & 0.019 & 0.139 & 0.118 & 0.981 \\
\hline
\end{tabular}
\end{table}

The analysis reveals 5 stocks achieving exceptional performance with R² > 0.98, representing 7.1\% of the total sample. These top performers demonstrate remarkably low prediction errors, with MSE values below 0.02 and RMSE below 0.14 \cite{Bao2017}. The standout performer 000333.SZ (Midea Group) achieved near-perfect prediction accuracy with R² = 0.994 and MSE = 0.004, indicating the model captures 99.4\% of the stock's return variance.
\begin{figure}[!ht] % Better placement options
    \centering
    % Adjust width, height, scale, or keep aspect ratio
    \includegraphics[width=0.80\textwidth]{Picture3.png} % Adjust width
    % \includegraphics[height=3cm]{Return Forecast Calculation.png} % Adjust height
    % \includegraphics[scale=0.5]{Return Forecast Calculation.png} % Scale image
    % \includegraphics[width=0.5\textwidth, height=5cm, keepaspectratio]{Return Forecast Calculation.png} % Keep aspect ratio

    \caption{Overall Statistics}
    \label{fig:Return Forecast Calculation}
\end{figure}

As shown in Fig. 3, the predictions demonstrate a strong linear relationship with actual values (r = 0.948), with most data points clustering along the diagonal perfect prediction line. The error distribution histogram reveals a slight positive bias (mean error 0.109), but 76\% of errors fall within the +/-0.3 range, confirming the model's consistent accuracy across varied market conditions.

% \textbf{Performance Distribution Analysis:} The comprehensive analysis of 70 stocks reveals a trimodal distribution pattern based on valid R² measurements from 41 stocks (58.6\% of sample). High performers (R² > 0.9) constitute 12.9\% of stocks with valid measurements, including standouts like 000333.SZ (R² = 0.994), 600519.SH (R² = 0.992), and 002352.SZ (R² = 0.990). Moderate performers (0.6 $\leq$ R² $\leq$ 0.9) represent 54.8\% of valid measurements, while challenging cases (R² < 0.6) account for 32.3\%. The presence of 29 stocks (41.4\%) with missing R² values, primarily due to negative variance explained, highlights systematic data quality challenges that warrant further investigation in model validation procedures.

% \vspace{0.3cm}

%\textbf{Challenging Prediction Cases:}

\begin{table}[!ht]
\renewcommand{\arraystretch}{1.5} % Increase row height
\centering
\large % Make table font slightly larger
\caption{\textbf{Poorly Performing Prediction Samples}}
\begin{tabular}{|l|c|c|c|c|l|}
\hline
\textbf{Stock} & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} & \textbf{$\mathbf{R^2}$} & \textbf{Sector} \\
\hline
601727.SH & 1.246 & 1.116 & 1.052 & -3.985 & Industrial \\
002385.SZ & 1.297 & 1.139 & 1.139 & N/A    & Agriculture \\
600340.SH & 0.101 & 0.318 & 0.318 & N/A    & Real Estate \\
\hline
\end{tabular}
\end{table}

% Stocks with poor predictive performance often exhibit one or more of the following: extreme volatility, small market capitalization, limited trading history, or contradictory technical indicators \cite{Malkiel2003, Campbell2001}. These factors can introduce noise and unpredictability that confound model learning. Additionally, such stocks may be subject to irregular trading volumes, low liquidity, or influence from speculative behavior, which further complicates reliable forecasting \cite{Black1976}. External shocks or sector-specific disruptions (e.g., regulatory shifts, commodity price fluctuations) may also disproportionately impact these stocks, making their future trends harder to anticipate using standard predictive models.

% \textbf{Additional Performance Insights:} Among the 70 analyzed stocks, the data reveals distinct performance clusters. The highest MSE values are observed in 002385.SZ (1.297) and 601727.SH (1.246), both exceeding 1.0, indicating substantial prediction errors. Conversely, 000333.SZ achieves the lowest MSE of 0.004, representing a 324-fold improvement over the worst performer. The distribution shows 29 stocks (41.4\%) with missing R² values, suggesting systematic data availability issues that may warrant further investigation in model validation procedures \cite{Shah2019}.
\subsection{Sector-Based Analysis}
To examine sector-specific performance patterns, stocks were categorized into five primary sectors: Technology, Consumer, Financial, Industrial, and Real Estate. This classification followed standard Global Industry Classification Standard (GICS) sector definitions \cite{MSCI2018}, with occasional adjustments for China-specific market characteristics. For each sector, performance metrics were aggregated using both simple averages and weighted averages based on market capitalization to avoid distortion from outlier stocks.

\begin{table}[!ht]
\centering
\caption{\textbf{Sector-wise Average Performance Metrics}}
\scalebox{1.2}{ % Increase size by 20%
\begin{tabular}{|l|c|c|c|c|c|} % Added sector column
\hline
\textbf{Sector} & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} & \textbf{$\mathbf{R^2}$} & \textbf{Representative Stocks} \\
\hline
Technology & 0.037 & 0.181 & 0.173 & 0.837 & 300750.SZ, 000063.SZ \\
Consumer & 0.023 & 0.136 & 0.129 & 0.863 & 600519.SH, 000333.SZ \\
Financial & 0.019 & 0.121 & 0.102 & 0.815 & 601628.SH, 601318.SH \\
Industrial & 0.068 & 0.243 & 0.229 & 0.681 & 002352.SZ, 601669.SH \\
Real Estate & 0.106 & 0.316 & 0.297 & 0.591 & 600340.SH, 000002.SZ \\
\hline
\end{tabular}
}
\end{table}

Statistical significance was evaluated using ANOVA tests \cite{Box1970} to confirm that the observed inter-sector differences in R\textsuperscript{2} values were not attributable to random variation (p $<$ 0.01). Further analysis employed post-hoc Tukey HSD tests \cite{Tukey1949} to identify which specific sector pairs exhibited statistically significant differences in predictability.

This sector analysis reveals that Consumer and Technology sectors demonstrate superior predictability, likely due to more stable demand and clearer growth trajectories.
As evident from the distribution of colored points in Fig. 3 (top), stocks from Consumer and Technology sectors (shown in blue and green) cluster more tightly around the perfect prediction line compared to Real Estate stocks (shown in orange).

% \subsection{Market Capitalization Impact}
% Performance improved monotonically with market size, stratified across five capitalization tiers:

\begin{table}[!ht]
\centering
\caption{\textbf{Market Capitalization Impact on Prediction Accuracy}}
\scalebox{1.2}{ % Scales the table to 120%
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Market Cap Tier} & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} & \textbf{$\mathbf{R^2}$} \\
\hline
Ultra Large & 0.006 & 0.076 & 0.071 & 0.945 \\
Large       & 0.025 & 0.149 & 0.142 & 0.853 \\
Medium      & 0.058 & 0.229 & 0.213 & 0.704 \\
Small       & 0.112 & 0.319 & 0.298 & 0.511 \\
Micro       & 0.238 & 0.459 & 0.421 & 0.298 \\
\hline
\end{tabular}
}
\end{table}

% Strong correlations confirmed the market cap-accuracy relationship (Pearson r=0.78, Spearman $\rho$=0.81, p<0.001). Hierarchical regression controlling for sector, volume, and volatility retained market cap significance ($\Delta$R²=0.23, p<0.001). Ultra-large-cap stocks like 000333.SZ (R²=0.994) and 600519.SH (R²=0.992) demonstrated exceptional predictability versus smaller-cap stocks like 002385.SZ (MSE=1.297).

\FloatBarrier
\subsection{Factor Influence Analysis}
Standardized regression analysis quantified relative factor impacts across all stocks:

\begin{table}[H]
\centering
\caption{\textbf{Factor Influence Analysis}}
\renewcommand{\arraystretch}{1.3} % Increases row height
\scalebox{1.2}{%
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Factor} & \textbf{Avg Impact} & \textbf{Std Dev} & \textbf{Observation} \\
\hline
Investment     & +3.64 & 1.87 & Strong positive indicator \\
Market         & +0.76 & 3.20 & Variable influence \\
Size           & -0.43 & 3.72 & Highly variable impact \\
Valuation      & -0.07 & 0.86 & Minimal overall effect \\
Profitability  & -1.29 & 3.38 & Moderate negative association \\
News Effect    & -4.86 & 0.28 & Strongly negative impact \\
\hline
\end{tabular}%
}
\end{table}

News Effect Factor showed remarkable consistency (-4.86±0.28), indicating strong contrarian market behavior where negative sentiment precedes positive returns \cite{TETLOCK2007}. 

\textbf{Error Distribution:} 3 ultra-low error stocks (MSE < 0.005, 4.3\%), 46 moderate error stocks (0.005 $\leq$ MSE $\leq$ 0.100, 65.7\%), and 21 high-error stocks (MSE > 0.100, 30.0\%) with extreme outliers 002385.SZ (MSE = 1.297) and 601727.SH (MSE = 1.246).

\section{Conclusion}

FinReport successfully integrates multi-factor models \cite{FAMA1993,Carhart1997} with news sentiment analysis \cite{TETLOCK2007,Araci2019} to deliver explainable stock forecasts. The system achieves $R^2$ of 0.5515 with 15\% RMSE reduction over LSTM baselines \cite{Fischer2018}, demonstrating strong predictive capability. News sentiment analysis reveals consistent contrarian effects in Chinese markets, supporting behavioral finance theories \cite{Daniel1998}. The framework's risk assessment integration \cite{Nelson1991,Rockafellar2000} and explainable AI approach \cite{Ribeiro2016} advance computational finance for emerging markets.

\FloatBarrier
% Add space to prevent vbox issues
\vspace*{-3pt} 

% \section*{Acknowledgements}

% Acknowledgements and Reference heading should be left justified, bold, with the first letter capitalized but have no numbers. Text below continues as normal.

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

% \appendix
% \section{An example appendix}
% Authors including an appendix section should do so before References section. Multiple appendices should all have headings in the style used above. They will automatically be ordered A, B, C etc.

% \subsection{Example of a sub-heading within an appendix}
% There is also the option to include a subheading within the Appendix if you wish.
% %% References
%%
%% Following citation commands can be used in the body text:
%% Usage of \cite is as follows:
%%   \cite{key}         ==>>  [#]
%%   \cite[chap. 2]{key} ==>> [#, chap. 2]
%%

%The citation must be used in following style: \cite{article-minimal} \cite{article-full} \cite{article-crossref} \cite{whole-journal}.
%% References with BibTeX database:

\bibliographystyle{elsarticle-num}
\bibliography{References}


%% Authors are advised to use a BibTeX database file for their reference list.
%% The provided style file elsarticle-num.bst formats references in the required Procedia style

%% For references without a BibTeX database:

% \begin{thebibliography}{}

%% \bibitem must have the following form:
%%   \bibitem{key}...
%%

% \bibitem{Massimo2011}
% {F}ilippini, Massimo, and Lester C. Hunt. (2011) ``Energy demand and
% energy efficiency in the OECD countries: a stochastic demand frontier
% approach." {\it Energy Journal} {\bf 32} (2): 59--80.
% \bibitem{Massimo2012}
% Filippini, Massimo, and Lester C. Hunt. (2012) ``US residential
% energy demand and energy efficiency: A stochastic demand frontier
% approach." {\it Energy Economics} {\bf 34} (5): 1484--1491.
% \bibitem{Thomas2015} 
% Weyman-Jones, Thomas, J\'{u}lia Mendon\c{c}a Boucinha, and Catarina
% Feteira In\'{a}cio. (2015) ``Measuring electric energy efficiency in
% Portuguese households: a tool for energy policy." {\it Management of Environmental Quality: An International Journal} {\bf 26} (3): 407--422.
% \bibitem{} 
% Saunders, Harry (2009) ``Theoretical Foundations of the Rebound Effect'', in Joanne Evans and Lester Hunt (eds) {\it International Handbook on the Economics of Energy}, Cheltenham, Edward Elgar
% \bibitem{} 
% Sorrell, Steve (2009) ``The Rebound Effect: definition and estimation'', in Joanne Evans and Lester Hunt (eds) {\it International Handbook on the Economics of Energy}, Cheltenham, Edward Elgar 
%  \end{thebibliography}

% \clearpage

%%%% This page is for instructions only, once the article is finalize please omit the below text before creating the final PDF
%\normalMode

% \section*{Instructions to Authors for LaTeX template:}

% \section{ZIP mode for LaTeX template:}

% The zip package is created as per the guide lines present on the URL http://www.elsevier.com/author-schemas/ preparing-crc-journal-articles-with-latex for creating the LaTeX zip file of Procedia LaTeX template.  The zip generally contains the following files:
% \begin{Itemize}[]\leftskip-17.7pt\labelsep3.3pt
% \item ecrc.sty
% \item  elsarticle.cls
% \item elsdoc.pdf
% \item .bst file
% \item Manuscript templates for use with these bibliographic styles
% \item  Generic and journal specific logos, etc.
% \end{Itemize}

% The LaTeX package is the main LaTeX template. All LaTeX support files are required for LaTeX pdf generation from the LaTeX template package. 

% {\bf Reference style .bst file used for collaboration support:} In the LaTeX template packages of all Procedia titles a new ``.bst'' file is used which supports collaborations downloaded from the path http://www.elsevier.com/author-schemas/the-elsarticle-latex-document-class

% \section{Reference style used in Computer Science:}
% \let\footnotesize\normalsize
% \hspace*{-10pt}\begin{tabular*}{\hsize}{@{}ll@{}}
% {\bf Title}&{\bf Reference style} \\[6pt]
% PROCS  & 3 Vancouver Numbered
% \end{tabular*}

% Final spacing adjustment to prevent vbox issues
\vfill
\clearpage

\end{document}

%%
%% End of file `procs-template.tex'.
